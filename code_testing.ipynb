{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# from operator import index\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import splitfolders\r\n",
    "import torch\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from torchvision import datasets, transforms\r\n",
    "\r\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def splitting(path):\r\n",
    "    if os.path.exists(\"data/dataset_splits\"):\r\n",
    "        return\r\n",
    "    else:\r\n",
    "        splitfolders.ratio(path, output=\"data/dataset_splits\", seed=1337, ratio=(.8, 0.1,0.1))\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "def dataset_loader(train_path, val_path, test_path):\r\n",
    "    train_transform = transforms.Compose([transforms.Resize(224),\r\n",
    "                                        transforms.RandomRotation(30),\r\n",
    "                                        transforms.RandomHorizontalFlip(),\r\n",
    "                                        transforms.ToTensor(),\r\n",
    "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406],\r\n",
    "                                        std=[0.229, 0.224, 0.225])])\r\n",
    "\r\n",
    "    val_transform = transforms.Compose([transforms.Resize(224, 224),\r\n",
    "                                        transforms.ToTensor(),\r\n",
    "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406],\r\n",
    "                                        std=[0.229, 0.224, 0.225])])\r\n",
    "\r\n",
    "    test_transform = transforms.Compose([transforms.Resize(224, 224),\r\n",
    "                                    transforms.ToTensor(),\r\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\r\n",
    "                                    std=[0.229, 0.224, 0.225])])\r\n",
    "\r\n",
    "    train_dataset = datasets.ImageFolder(train_path, transform=train_transform)\r\n",
    "    val_dataset = datasets.ImageFolder(val_path, transform=val_transform)\r\n",
    "    test_dataset = datasets.ImageFolder(test_path, transform=test_transform)\r\n",
    "    print(f\"Training data samples:{len(train_dataset)}\\nValidation data samples:\\\r\n",
    "         {len(val_dataset)}\\nTesting data samples: {len(test_dataset)}\")\r\n",
    "\r\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\r\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=16)\r\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16)\r\n",
    "\r\n",
    "    print('Data DUELY HANDLED')\r\n",
    "\r\n",
    "    return train_loader, val_loader, test_loader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_loader, val_loader, test_loader = dataset_loader(\"data/dataset_splits/train\", \"data/dataset_splits/val\", \"data/dataset_splits/test\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "images, labels = iter(train_loader).next()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "import torchvision"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class_names = [cat for cat in os.listdir(\"data/2750\")]\r\n",
    "class_names"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def imshow(inp, title=None):\r\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\r\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\r\n",
    "    mean = np.array([0.485, 0.456, 0.406])\r\n",
    "    std = np.array([0.229, 0.224, 0.225])\r\n",
    "    inp = std * inp + mean\r\n",
    "    inp = np.clip(inp, 0, 1)\r\n",
    "    plt.imshow(inp)\r\n",
    "    if title is not None:\r\n",
    "        plt.title(title)\r\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\r\n",
    "\r\n",
    "\r\n",
    "# Get a batch of training data\r\n",
    "inputs, classes = next(iter(train_loader))\r\n",
    "\r\n",
    "# Make a grid from batch\r\n",
    "out = torchvision.utils.make_grid(inputs)\r\n",
    "\r\n",
    "plt.figure(figsize=(20,10))\r\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torch import nn\r\n",
    "import torch.nn.functional as F\r\n",
    "from torchvision import models"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class SatImgNet(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(SatImgNet, self).__init__()\r\n",
    "        self.fc1 = nn.Linear(2048, 256)\r\n",
    "        self.fc2 = nn.Linear(256, 10)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = F.relu(self.fc1(x))\r\n",
    "        x = self.fc2(x)\r\n",
    "\r\n",
    "        return x\r\n",
    "\r\n",
    "\r\n",
    "model = models.resnet50(pretrained=True)\r\n",
    "\r\n",
    "for param in model.parameters():\r\n",
    "    param.requires_grad = False\r\n",
    "\r\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\r\n",
    "model.fc = SatImgNet()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch.optim as optim\r\n",
    "\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\r\n",
    "\r\n",
    "    running_loss = 0.0\r\n",
    "    for i, data in enumerate(train_loader, 0):\r\n",
    "        # get the inputs; data is a list of [inputs, labels]\r\n",
    "        inputs, labels = data\r\n",
    "\r\n",
    "        # zero the parameter gradients\r\n",
    "        optimizer.zero_grad()\r\n",
    "\r\n",
    "        # forward + backward + optimize\r\n",
    "        outputs = model(inputs)\r\n",
    "        loss = criterion(outputs, labels)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        # print statistics\r\n",
    "        running_loss += loss.item()\r\n",
    "        if i % 50 == 49:    # print every 50 mini-batches\r\n",
    "            print('[%d, %5d] loss: %.3f' %\r\n",
    "                  (epoch + 1, i + 1, running_loss / 50))\r\n",
    "            running_loss = 0.0\r\n",
    "\r\n",
    "print('Finished Training')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit (conda)"
  },
  "interpreter": {
   "hash": "fd28f81d38287ab3bf6f466aa2ccd2a6801c40dbbb1d3a442c76f0cac2167521"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}